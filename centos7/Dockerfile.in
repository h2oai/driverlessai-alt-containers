FROM nvidia/cuda:10.0-cudnn7-devel-centos7

RUN \
    yum clean all -y && rm -rf /var/cache/yum && \
    yum install -y \
        freetype \
        less \
        which \
        wget \
        graphviz \
        gcc gcc-c++ \
        libjpeg-turbo-devel \
        unzip && \
    yum clean all -y && rm -rf /var/cache/yum

RUN \
    bash -c \
        'if [ `arch` = "x86_64" ]; then \
             mkdir -p /etc/OpenCL/vendors && \
             echo "libnvidia-opencl.so.1" > /etc/OpenCL/vendors/nvidia.icd; \
         fi'

ARG DAI_URL=https://s3.amazonaws.com/artifacts.h2o.ai/releases/ai/h2o/dai/rel-1.8.6-31/x86_64-centos7/dai-1.8.6-1.x86_64.rpm

COPY python_deps.txt /tmp

RUN \
    set -ex && \
    curl -s -o dai.rpm "${DAI_URL}" && \
    rpm -i dai.rpm && \
    rm -rf /opt/h2oai/dai/lib/cuda-10.0 && \
    echo "docker" > /opt/h2oai/dai/metadata/package_type && \
    /opt/h2oai/dai/dai-env.sh pip install --no-cache-dir jupyter notebook==5.6.0 -c /tmp/python_deps.txt && \
    rm -fr dai.rpm && \
    rm -rf /opt/h2oai/dai/tmp && \
    ln -s /tmp /opt/h2oai/dai/tmp && \
    mkdir /log && \
    chmod -R o+w /log && \
    rm -rf /opt/h2oai/dai/log && \
    ln -s /log /opt/h2oai/dai/log && \
    chmod -R a-w /opt/h2oai/dai/python && \
    chmod -R a-w /opt/h2oai/dai/cuda-10.0 && \
    chmod -R a-w /opt/h2oai/dai/cpu-only && \
    chmod -R o+rwx /opt/h2oai/dai/home

# Download pretrained image recognition model(s) - for more, see config.tensorflow_image_pretrained_models
RUN \
    mkdir -p /opt/h2oai/dai/pretrained/image/ && \
    chmod -R o+w /opt/h2oai/dai/pretrained && \
    ln -sf /opt/h2oai/dai/pretrained /pretrained && \
    mkdir -p /h2oai/ && \
    ln -sf /opt/h2oai/dai/pretrained /h2oai/pretrained && \
    cd /opt/h2oai/dai/pretrained/image/ && \
    wget -q https://s3.amazonaws.com/artifacts.h2o.ai/releases/ai/h2o/pretrained/image/xception_keras.model

# Make a default directory where license files can be stored inside the container.
# To make these persist across container sessions, mount a volume over this point.
RUN \
    mkdir /license && \
    chmod -R o+w /license

#
# Prepare /etc/passwd for modification (this is required to support HDFS client).
# See: https://blog.openshift.com/jupyter-on-openshift-part-6-running-as-an-assigned-user-id/
#
RUN chmod o+w /etc/passwd

# Add shell wrapper.
COPY run.sh /run.sh

# Set home directory for docker user, whether it be root or not.
# This was made world writable earlier.
ENV HOME /opt/h2oai/dai/home

# Remove Python 2
RUN \
    rpm -e --nodeps python

ENTRYPOINT ["./run.sh"]

EXPOSE 8888
EXPOSE 12345